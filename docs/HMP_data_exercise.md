# HMP Data Exercise
<a name="top"></a>
This document walks you through the steps of extracting data from the HMP Cloud Archive and completing the following analysis tasks.

* [Compare 16S and WGS community profiles for a body site](#compare_16s_wgs)
* [Compare the 16S community profiles for two different body sites](#compare_16s_across_sites)
* [Analyze 16S and WGS community profiles for a body site](#analyze_16s_wgs)
* [Analyze the 16S community profiles for two different body sites](#analyze_16s_across_sites)

[top](#top)
## <a name="compare_16s_wgs"></a> Compare 16S and WGS community profiles for a body site

The comparison of the 16S and corresponding WGS data is completed using the community profiles generated by Qiime and MetaPhlAn2 at the genus level. In this exercise you will download the precomputed community profiles, generate a list of a subset of samples for a particular body site and visit where we have both 16S and WGS data, and then extract the community profiles for this subset of samples. Once you have these subset profiles you will import them into Metaviz to compare the profiles graphically.


### <a name="download_profiles"></a> Download Qiime and MetaPhlAn Community Profiles
In the data_exercise directory you will find a GDC manifest file which has the information that the GDC Client needs to download the precomputed community profiles. Copy the manifest file to the local working directory and run the following command to download the profiles:

```
gdc_client hmp_data_exercise.manifest
```

This should download the following files:

    hmp1-II_metaphlan2-mtd-qcd.pcl.txt

    v35_psn_otu.genus.fixed.txt

### Create a list of samples where we have 16S and WGS data
In the data_exercise directory you will find the files that have the metadata associated with 16S and WGS data. Copy the two files (16s_metadata.tsv, wgs_metadata.tsv) to the local working directory.

<a name="hmp_bodysites"></a>The HMP samples were collected from the following body sites:
```
Anterior_nares
Buccal_mucosa
Hard_palate
Keratinized_gingiva
L_Retroauricular_crease
Mid_vagina
Palatine_Tonsils
Posterior_fornix
R_Antecubital_fossa
R_Retroauricular_crease
STSite
Saliva
Stool
Subgingival_plaque
Supragingival_plaque
Throat
Tongue_dorsum
Vaginal_introitus
```
However, for this exercise we will use samples from the first visit for the following three body sites: "Anterior_nares", "Stool", and "Posterior_fornix".

#### Create a list of samples that will be used for the exercise.
Use the script generate_matched_visit_samples.R to create a list of randomized samples from a particular body site and visit. The usage of the script is described below.

```
Usage:
generate_matched_visit_samples.R
    -[-m16s|s] <16S metadata file>
    -[-wgs|w] <WGS metadata file>
    -[-bodysite|b] <bodysite>
    -[-visit|v] <visit number>
    -[-count|c] <rand subject count>
    [-[-help|h]]

```
The following command will extract matched samples for 25 randomly selected subjects from the Stool samples. The output is written to the file bodysite_rand_samples.txt

```
Rscript generate_matched_visit_samples.R --wgs wgs_metadata.tsv \
  --m16s 16s_metadata.tsv --count 25 --visit 1 --bodysite Stool
```

#### Create a list of samples that will be used for the exercise.
Use the script extract_subset.R to take the list of samples identified in the previous step and the community profiles generated by Qiime and MetaPhlAn2 and extract out the profiles for these matched samples.

```
Usage:
extract_subset.R
    -[-qiime|q] <Qiime OTU table>
    -[-metaphlan|m] <MetaPhlAn2 Abundance Table>
    -[-samples|s] <Samples file from previous step>
    [-[-help|h]]
```

The following command will generate the abundance matrices for the specified subset of samples.
```
Rscript extract_subset.R --qiime v35_psn_otu.genus.fixed.txt \
  --samples Stool_rand_samples.txt --metaphlan hmp1-II_metaphlan2-mtd-qcd.pcl.txt
```
[Top](#top)

## <a name="compare_16s_across_sites"></a> Compare the 16S community profiles for two different body sites

The comparison of the 16S data across two body sites is completed using the community profiles generated by Qiime. In this exercise you will download the precomputed community profiles, generate a list of a subset of samples for the two body sites and a particular visit, and then extract the community profiles for this subset of samples. Once you have these subset profiles you will import them into Metaviz to compare the profiles graphically.


### Download Qiime Community Profiles
You should already have the community profiles downloaded from the previous exercise, if not see the section [Download Qiime and MetaPhlAn Community Profiles](#download_profiles) to download the files.

### Create a list of samples where we have 16S data for the two specified body sites
In the data_exercise directory you will find the files that have the metadata associated with 16S samples. Copy the file (16s_metadata.tsv) to the local working directory.

For this exercise we will use samples from the first visit for the following two body sites: "Anterior_nares" and "Stool".

#### Create a list of two body site samples that will be used for the exercise.
Use the script generate_matched_two_site_samples.R to create a list of randomized samples from two body sites and a particular visit. The usage of the script is described below.

```
Usage:
generate_matched_visit_samples.R
    -[-outfile|o] <character>
    -[-bodysite1|a] <character>
    -[-bodysite2|b] <character>
    -[-region|r] <character>
    -[-visit|v] <visit number>
    -[-count|c] <rand subject count>
    [-[-help|h]]

```
The following command will extract matched samples for 25 randomly selected subjects from the Stool samples. The output is written to the file bodysite_rand_samples.txt

```
Rscript generate_matched_two_site_samples.R --m16s 16s_metadata.tsv --visit 1 \
  --count 20 --bodysite1 Stool --bodysite2 Anterior_nares \
  --outfile  stool_nares_subsamples.tsv \
  --region V35
```

#### Create a list of samples that will be used for the exercise.
Use the script extract_subset.R to take the list of samples identified in the previous step and the community profiles generated by Qiime and MetaPhlAn2 and extract out the profiles for these matched samples.

```
Usage:
extract_qiime_subset.R
    -[-qiime|q] <Qiime OTU table>
    -[-samples|s] <Samples file from previous step>
    -[-outfile|o] <character>    
    [-[help|h]]
```

The following command will generate the abundance matrices for the specified subset of samples.
```
Rscript extract_qiime_subset.R --qiime v35_psn_otu.genus.fixed.txt \
  --samples stool_nares_subsamples.tsv --outfile stool_nares_subsamples_v35_psn_otu.genus.fixed.txt
```

[top](#top)
## <a name="analyze_16s_wgs"></a> Analyze 16S and WGS community profiles for a body site

In this part of the exercise you will first analyze the 16S and WGS using Qiime/Qiita and MetaPhlAn2. You will take the results from this analysis and then compare the data generated by these tools at the genus level.

### Download data
In this part of the exercise you will use the [HMP data transfer tool](https://github.com/IGS/hmp_client), which has already been installed on your machine, to download files from Amazon Cloud to your machine in EC2 or local machine for analysis. The data transfer tool works on a manifest file that you will have generated previously (for this exercise we have pre generated manifest file that you will use) using the [HMP Query interface](http://portal.ihmpdcc.org).

Copy the manifest file Stool_rand_manifest.tsv in the examples directory to the local directory and use the script client.py to download the data files specified in the manifest file.

```
Usage:
usage: hmp_client
    [-h] (-manifest MANIFEST | -url URL | -token TOKEN)
    [-destination DESTINATION]
    [-endpoint_priority ENDPOINT_PRIORITY]
    [-block_size BLOCK_SIZE]
    [-retries RETRIES]

```
The following command will extract matched samples for 25 randomly selected subjects from the Stool samples. The output is written to the current working directory.

```
hmp_client -manifest stool_rand_wgs_manifest.tsv -destination stool_wgs
hmp_client -manifest stool_rand_16s_manifest.tsv -destination stool_16s
```
This will download trimmed 16S sequences and the corresponding WGS samples for the 25 randomly selected subject visits to the directory specified by the <em>destination</em> directory.

### Launch workflows to analyze downloaded data
To make the usage of the Docker images and for the ease of the exercises, we have built simple scripts that can create workflows defined in the Common Workflow Language (CWL). These workflows can be executed using the <em>cwl-runner</em>, a command-line tool to execute the workflows. The workflow runner uses the predefined Docker containers in batch modes to complete the analysis tasks. You can find workflows for all the tools used in this workshop including Qiime, HUMAnN2, MetaCompass, and StrainPhlAn.

[top](#top)

#### Launch workflow to analyze the 16S data using Qiime
```
Usage:
usage: create_qiime_workflow
    [-h]
    -data_dir <character> (location of the files to process)
    -out_dir <character> (location of analysis results)

```
The following command will run the Qiime process on all the files in the specified data directory.

```
create_qiime_workflow -data_dir stool_16s -out_dir stool_16s_results
```

This workflow will process the individual files in the specified data directory and write the individual OTU tables. It will then create a combined OTU table for all the samples.

[top](#top)
#### Launch the workflows to analyze the WGS data using HUMAnN2
```
Usage:
usage: create_humann2_workflow
    [-h]
    -data_dir <character> (location of the files to process)
    -out_dir <character> (location of analysis results)

```
The following command will run the HUMAnN2 process on all the files in the specified data directory.

```
create_qiime_workflow -data_dir stool_wgs -out_dir stool_wgs_results
```

This workflow will process the individual files in the specified data directory and write the individual MetaPhlAn2 and HUMAnN2 tables. It will then create a combined relative abundance table for all the samples based on MetaPhlAn2 results.

[top](#top)
## <a name="analyze_16s_wgs"></a>Analyze the 16S community profiles for two different body sites

In this part of the exercise you will first analyze the 16S data using Qiime. You will take the results from this analysis and then visualize and compare the data generated for the two body sites using Metaviz.

[top](#top)
# Related Links:

- [Discussion group site](https://groups.google.com/forum/#!forum/hmp-cloud-pilot) (Google groups, for collaborators)
- [HMP Query interface](http://portal.ihmpdcc.org) - Click 'data' to get the facet search
- [HMP Client](https://github.com/IGS/hmp_client) - HMP Data Transfer Tool is a command line client to download data from the HMP data repository to local machine using a manifest file generated through the query interface.
- [Common Workflow Language]() - The common workflow language used in Chiron

[top](#top)
